# ProductPulse Usability Testing Guide

## Overview
- **Goal:** Evaluate ProductPulse usability with 3-5 participants
- **Duration:** 20-30 minutes per session
- **Method:** Think-aloud protocol + task completion

---

## Pre-Test Setup

### Environment
- [ ] ProductPulse running (locally or deployed)
- [ ] Screen recording ready (Zoom, OBS, or Loom)
- [ ] Note-taking document open
- [ ] Test project data cleared (fresh start for each participant)

### Participant Criteria
- Product managers, data analysts, or developers
- Familiar with product feedback concepts
- No prior experience with ProductPulse

---

## Test Script

### Introduction (2 minutes)
Read to participant:

> "Thank you for participating in this usability test. I'm testing an AI-powered tool called ProductPulse that helps product managers monitor feedback from public forums.
>
> During this session, I'll ask you to complete several tasks. Please think out loud as you work - tell me what you're looking at, what you're trying to do, and any confusion you experience.
>
> This is a test of the product, not of you. There are no wrong answers. Your honest feedback helps improve the tool.
>
> Do you have any questions before we begin?"

---

### Task 1: Create a Project (3-4 minutes)
**Instructions to participant:**
> "Imagine you're a product manager for [Slack/Notion/any product they know]. Create a new project to track feedback about this product."

**Observe:**
- [ ] Can they find "New Project"?
- [ ] Do they understand the form fields?
- [ ] Do they use AI keyword suggestions?
- [ ] Any confusion points?

**Success criteria:** Project created with name, description, and at least 2 keywords

---

### Task 2: Add Competitors (2-3 minutes)
**Instructions to participant:**
> "Add some competitors that you'd like to track alongside your product."

**Observe:**
- [ ] Do they find the competitors section?
- [ ] Do they try "Discover Competitors"?
- [ ] Can they add competitors successfully?

**Success criteria:** At least 1 competitor added

---

### Task 3: Add Data Sources (3-4 minutes)
**Instructions to participant:**
> "Add some sources where you'd expect to find feedback about this product."

**Observe:**
- [ ] Do they find "Suggest Sources"?
- [ ] Do they understand source types (Reddit, HN, etc.)?
- [ ] Can they select and add sources?

**Success criteria:** At least 2 sources added

---

### Task 4: Fetch Content (2-3 minutes)
**Instructions to participant:**
> "Now fetch some content from these sources to analyze."

**Observe:**
- [ ] Can they find the fetch button?
- [ ] Do they understand the fetching process?
- [ ] Any confusion about waiting?

**Success criteria:** Fetch initiated successfully

---

### Task 5: Find Negative Feedback (2-3 minutes)
**Instructions to participant:**
> "Find feedback that has negative sentiment."

**Observe:**
- [ ] Can they navigate to Insights?
- [ ] Do they find the sentiment filter?
- [ ] Can they interpret the results?

**Success criteria:** Negative sentiment filter applied

---

### Task 6: Filter by Competitor (2-3 minutes)
**Instructions to participant:**
> "Find feedback that mentions one of your competitors."

**Observe:**
- [ ] Do they find the competitor filter?
- [ ] Do they understand what it does?
- [ ] Can they apply it successfully?

**Success criteria:** Competitor filter applied

---

### Task 7: Export Data (1-2 minutes)
**Instructions to participant:**
> "Export the insights data to share with your team."

**Observe:**
- [ ] Can they find the Export button?
- [ ] Does the download work?

**Success criteria:** CSV downloaded

---

### Debrief Questions (3-5 minutes)

1. "What was your overall impression of ProductPulse?"
2. "What did you find most useful?"
3. "What was confusing or frustrating?"
4. "Would you use this tool in your work? Why or why not?"
5. "What features would you add or change?"
6. "On a scale of 1-10, how easy was it to use?"

---

## Recording Template

### Participant #[X]

**Date:** ___________  
**Background:** ___________  
**Duration:** ___________

#### Task Completion

| Task | Completed? | Time | Notes |
|------|------------|------|-------|
| 1. Create Project | Yes/No/Partial | | |
| 2. Add Competitors | Yes/No/Partial | | |
| 3. Add Sources | Yes/No/Partial | | |
| 4. Fetch Content | Yes/No/Partial | | |
| 5. Find Negative | Yes/No/Partial | | |
| 6. Filter Competitor | Yes/No/Partial | | |
| 7. Export Data | Yes/No/Partial | | |

#### Confusion Points
1. 
2. 
3. 

#### Positive Feedback
1. 
2. 
3. 

#### Suggestions
1. 
2. 

#### Key Quote
> "..."

#### Ease of Use Rating: ___/10

---

## Summary Template (After All Tests)

### Overall Findings

**Task Success Rates:**
| Task | Success Rate |
|------|--------------|
| Create Project | X/Y |
| Add Competitors | X/Y |
| Add Sources | X/Y |
| Fetch Content | X/Y |
| Find Negative | X/Y |
| Filter Competitor | X/Y |
| Export Data | X/Y |

**Average Ease of Use:** ___/10

### Top 3 Successes
1. 
2. 
3. 

### Top 3 Pain Points
1. 
2. 
3. 

### Recommended Improvements
1. 
2. 
3. 

### Notable Quotes
> Quote 1

> Quote 2

---

## Checklist After Testing
- [ ] Compile all participant notes
- [ ] Calculate success rates
- [ ] Identify patterns in feedback
- [ ] Prioritize improvements
- [ ] Add findings to ASSIGNMENT.md Part 3
